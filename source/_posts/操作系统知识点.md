---
title: 操作系统知识点
tags:
  - 操作系统
description: |
  文章缩略，支持 `Markdown` **文档格式**
pinned: 0
lang: zh
categories:
  - 操作系统
type: post
wordCount: 143
charCount: 9682
imgCount: 0
vidCount: 0
wsCount: 0
cbCount: 0
readTime: 约59秒
abbrlink: 38059bce
date: 2025-10-28 16:46:23
---
<!-- toc -->

## 一、操作系统基础

### 1、什么是操作系统

​    操作系统（Operating System 简称 OS）本质上是一个运行在计算机上的软件程序，用于管理计算机硬件和软件资源。例如，运行在电脑上的所有应用程序都是通过操作系统来调用系统内存以及磁盘等硬件。



### 2、操作系统的内核

​    操作系统的内核时操作系统的核心部分，负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。内核时连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。



### 3、用户态和系统态

- 用户态：用户态运行的进程可以直接读取用户程序的数据
- 系统态：可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制，包括内存、CPU 指令等



### 4、系统调用

​    运行的程序基本都是运行在用户态，如果需要调用操作系统提供的系统态级别的子功能，就需要切换到系统态来调用。也就是说，运行的用户程序中，凡是与系统态级别的资源有关的操作（如 文件管理，进程控制，内存管理等），都必须通过系统调用方式向操作系统提出服务，并由操作系统代为完成。

​    系统调用大致分为一下几类：

- 设备管理。完成设备的请求或释放，设备启动等功能。
- 文件管理。完成文件的读、写、创建、删除等功能。
- 进程管理。完成进程的创建、撤销、阻塞、唤醒等功能。
- 进程通信。完成进程之间的消息传递或信号传递等。
- 内存管理。完成内存的分配、回收、获取作业占用内存大小以及地址等。

## 二、进程和线程

### 1、进程和线程的区别

- **进程**：操作系统进行**资源分配的基本单位**（如内存、CPU 时间片、文件句柄等），可理解为 “一个正在运行的程序实例”（例如打开的 Chrome 浏览器、一个 Java 程序），是一个独立的 “资源容器”。
- **线程**：操作系统进行**任务调度的基本单位**，是进程内的 “最小执行单元”（例如 Chrome 的一个标签页渲染线程、Java 程序的`main`线程），必须依赖进程存在，无法独立运行。

​    从 JVM 的角度看，一个进程可以有多个线程，多个线程共享进程的**堆**和**方法区**，但是每个线程都有自己的**程序计数器**、**虚拟机栈**、**本地方法栈**。线程是进程划分成的更小的运行单元，一个进程在其执行的过程中可以产生多个线程。线程和进程最大的不同在于，进程之间是相互独立的，而线程之间不一定，因为同一个进程中的线程极有可能相互影响。线程执行开销小，但是不利于资源的管理和保护，而进程正相反。



### 2、进程有哪几种状态

- **创建状态** ：进程正被创建。
    - 引起进程创建原因：用户登录、作业调度、提供服务、应用请求 都会引起进程的创建。
- **就绪状态** ：进程已处于准备运行状态，即 进程获得了除处理器以外的一切所需的资源，一旦得到处理器资源，即可运行。
- **运行状态** ：进程正在处理器上运行。
- **阻塞状态** ：进程正在等待某一事件而暂停运行，即使处理器处于空闲状态，该进程也不能运行，是进程主动提出
    - 原因：向操作系统请求共享资源失败、等待某种操作的完成、新数据尚未、等待IO操作的结束。
- **终止状态** ：进程终止运行。
    - 原因：正常结束、异常结束、外界干预。

补充：

- **进程的挂起** ：当系统中出现引起进程挂起的事件时，OS 会利用挂起原语将指定的进程挂起，如果进程时就绪状态，则改为静止就绪状态，如果是阻塞状态，则改为静止阻塞，如果运行状态，则将其转向调度程序重新调度。
- **进程的激活** ：当系统中出现激活进程的事件后，OS 会利用原语将指定的进程激活。



### 3、进程间的通信方式

- **管道通信**
    - 匿名管道：用于父进程和子进程之间的通信。
    - 有名管道：用于任意两个进程之间的通信。
- **信号**：信号是一种比较复杂的通信方式，用于通知接收进程有某种事件发生。
- **消息队列**：消息队列是消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道不同的是消息队列存放在内核中，只有在内核重启或者显示地删除一个消息队列时，该消息才会被真正的删除。消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按照消息的类型读取。**消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。**
- **信号量** ：信号量是一个计数器，常被作为一种**锁机制**，用于多进程对共享数据的访问，信号量主要作为进程间以及同一进程内不同线程间的同步手段。
- **共享内存** ：共享内存可以使运行在同一台机器上的进程间的**通信最快**。使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存种数据的更新，这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。
- **套接字** ：此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持TCP/IP的网络通信的基本操作单元，可以看作是不同主机之间的进程进行双向通信的端点，简单来说就是通信双方的一种约定，用套接字的相关函数来完成通信过程。



### 4、线程间的同步方式

​    线程同步是两个或多个共享资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步方式。

- **互斥量** ：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。例如：Java 中的synchronized 关键字和各种Lock都是这种机制。

- **信号量** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。

- **事件** ：通过通知操作（挂起和唤醒）的方式来保持多线程同步，还可以方便的实现多线程优先级得比较操作。



### 5、进程的调度

​    进程调度的任务主要有三，① 保存CPU现场信息 ② 按照某种算法选取进程 ③ 把 CPU 分配给该进程

​    进程调度算法一般有四种：

- **先到先服务** ： 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某种事件而被阻塞放弃占用CPU资源时再重新调度。

- **短作业优先** ：从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某种事件而被阻塞放弃占用CPU资源时再重新调度。
    - 缺点：必须预先知道作业的运行时间，但是这个时间很难估计准确，如果偏短，系统可能会提前终止进程。
    - 缺点：对长作业非常不利，周转时间会明显增长。
    - 缺点：完全没有考虑作业的紧迫程度。

- **时间片轮转** ：时间片轮转调度是一种古老，最简单，最公平且使用最广的调度算法，每个进程被分配一个时间段，称作它的时间片，也就是该进程允许运行的时间。

- **多级反馈队列** ：**短进程优先** 仅照顾了短进程，而忽略了长进程。而多级返回调度算法既能使高优先级的作业得到响应，又能响应短作业进程迅速完成，因此是被公认的最好的调度算法，UNIX 采用的就是这种调度算法。
    - 机制：① 设置多个就绪队列
    - 机制：② 每个队列都采用先来先服务调度算法
    - 机制：③ 按队列优先级调度

- **优先级调度** ：为每个进程分配优先级，首先执行具有高优先级的进程，以此类推，具有相同优先级的进程以先进先出的顺序执行。可以根据内存要求，时间要求或者任何其他资源的要求来确定优先级。



### 6、什么是死锁

​    死锁描述的是这样一种情况，多个进程/线程同时被阻塞，他们中的一个或全部都在等待某个资源被释放，但他们都会因为不能不能获得自己的资源去继续运行而无法释放自己当下占有的资源，并且一直处于这样的僵持状态，而形成死锁。



### 7、产生死锁的四个必要条件

- **互斥条件** ：资源必须处于非共享模式，即：一次只有一个进程可以使用。如果另一个进程申请该资源，那么必须等待直到该资源被释放为止。
- **请求和保持条件** ：一个进程至少占有了一个资源，并等待另一个资源，而该资源被其它线程所占有。
- **不可抢占条件** ： 资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
- **循环等待条件** ：一组进程`{P0,P1,...,Pn}` `P0` 等待的资源被 `P1`占有，`P1` 等待的资源被`P2` 占有，最后 `Pn` 等待的资源被`P1` 占有，形成循环等待的情况。

> 这四个条件是产生死锁的 **必要条件** ，也就是说只要系统发生死锁，这些条件必然成立，而只要让上述条件之一不满足，就不会产生死锁。



### 8、解决死锁的方法

#### 1、死锁的预防

​		**预防死锁** ：是采用某种策略，**限制并发进程对资源的请求**，从而使得死锁的必要条件在系统执行的任何时间都不满足。

​		只要破坏四个必要条件中的一个就能够预防死锁的发生。

​    	破坏第一个条件 **互斥条件** ：使得资源可以同时被访问，这种是最简单的方法，磁盘可以用这种方法管理，但是系统中的很多资源 **往往是不能被同时访问的** ，所以这种做法在大多数场合是行不通的。

​    	破坏第三个条件 **不可抢占条件** ：也就是说，可以采用 **剥夺式调度算法** ，但是，这种调度算法实现起来比较复杂，并且一个资源在被使用一段时间后被抢占，可能导致进程前一段时间的工作失效，还可能因为反复申请和释放资源导致进程的执行被无限期的推迟，既增加了系统开销，也降低了吞吐量。

​    	所以，一般比较实用的预防死锁的方法是，通过破坏第二个条件和第四个条件。

1. **静态分配策略**

​    静态分配策略就是指一个进程必须在执行前就申请到它所需要的全部资源，否则直到它所要的资源得到满足后才开始运行。进程要么占有所有资源开始运行，要么不占有资源，不会出现一些资源等待一些资源的情况。

​    静态分配策略逻辑简单，实现也很容易，但这种策略 **严重地降低了资源利用率**，因为在每个进程所占有的资源中，有一些资源是在比较靠后的执行时间里才用的，甚至有些资源是在额外的情况下才使用的，这样就可能造成一个进程占有了一些 **几乎不用的资源而是使用其他需要该资源的进程产生等待** 的情况。

1. **2、层次分配策略**

​    层次分配策略破坏了产生死锁的第四个条件，在层次分配策略下，所有的资源被分成了多个层次，一个进程得到某一次的一个资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源，这种策略，是不能可能出现循环等待链的，因为那样的话，就出现了已经申请了较高层的资源，反而去申请了较低层的资源，不符合层次分配策略。

#### 2、避免死锁

​		**避免死锁** ：是系统在分配资源时，根据资源的使用情况**提前做出预测**，从而**避免死锁的发生**

​		死锁的避免的角度是允许系统中**同时存在四个必要条件**，只要掌握并发进程中与每个进程有关的资源动态申请情况，做出 **明智合理的选择**，仍可以避免死锁，因为四大条件仅仅是产生死锁的必要条件。

​    可以将系统分为 **安全状态** 和 **不安全状态** ，每当为申请者分配资源前，先检测系统状态，如果把系统资源分配给申请者会产生死锁，则拒绝分配，否则接受申请，并为它分配资源。

> 安全状态，如果操作系统能够保证所有进程在有限时间内得到需要的全部资源，否则是不安全状态

​    	避免死锁的算法是，**银行家算法** ，也就是：当一个线程申请使用资源时，**银行家算法** 通过 **试探** 分配给该进程资源，然后通过 **安全性算法** 分析分配后系统是否处于安全状态，若处于不安全状态，则试探分配作废，让该进程继续等待，若能够进入安全状态，则就**真的分配资源给该进程**

#### 3、死锁的检测

​		**检测死锁** ：是指系统设有**专门的机构**，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源。

​		这种方法对资源的分配不加以限制，也不采取死锁避免的措施，但系统会**定时地运行一个 “死锁检测” 的程序**，判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解除它。

​		可以利用 **进程-资源分配图** 是否又环路来检测死锁，但是，有环路不一定死锁。



#### 4、死锁的解除

​		**解除死锁** ：是与检测相配套的一种措施，用于**将进程从死锁状态下解脱出来**

​		当死锁检测程序检测到存在死锁发生时，应设法让其解除，让系统从死锁中恢复过来。

- **立即结束所有进程的执行，重新启动操作系统**，方法简单，但是之前的工作全部作废，损失很大。
- **撤销涉及死锁的所有进程，解除死锁后继续运行**，彻底打破死锁的循环等待条件，付出的代价也较大，例如一个进程计算了很长时间，由于被撤销，部分结果也被消除，重新执行就要再次计算。
- **逐个撤销涉及死锁的进程，回收资源直到死锁解除**
- **抢占资源**，从涉及死锁的一个或几个进程中抢占资源，再把夺到的资源分配出去，知道死锁解除。

## 三、操作系统内存管理基础

### 1、内存管理介绍

​		操作系统的内存管理主要负责内存的分配和回收，另外地址转换也就是将逻辑地址转换为相应的物理地址等功能也是操作系统内存管理的事情。



### 2、内存管理机制与方式

​		简单的分为 **连续分配管理方式** 和 **非连续分配管理方式** 这两种。连续分配管理方式是指为一个用户程序分配一段连续的内存空间，常见的如 **块式管理**。同样的，非连续分配管理方式，允许一个程序使用的内存分布在离散或者说不相邻的内存空间中，常见的有 **页式管理** 、 **段式管理**、**段页式管理**。

1. **块式管理**：远古时代的计算机操作系统的内存管理方式。将内存分为几个固定大小的块，每个块只包含一个进程。如果程序需要内存的话，操作系统就分配给它一个块，如果程序运行只需要很小的空间的话，分配的这个块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。

2. **页式管理**：把主存分为大小相等且固定的一页一页的形式，页比较小，相比于块式管理，划分粒度更小，提高了内存的利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。

   地址转化：

   `逻辑地址 = 页号（Page Number） + 页内偏移（Offset）`

   `物理地址 = 页框号（Frame Number） + 页内偏移（Offset）`

3. **段式管理**：页式管理虽然提高了内存利用率，但是页式管理中的页并无任何实际的意义。段式管理把主存分为一段一段的，段是有实际的意义的，每个段顶一了一组逻辑信息，例如，有主程序段、子程序段、数据段、栈段等。段式管理通过段表对应的逻辑地址和物理地址。

   地址转换：

   `逻辑地址 = 段号（Segment Number） + 段内偏移（Offset）`

   `物理地址 = 段基址（Base Address） + 段内偏移（Offset）`

4. **段页式管理**：段页式管理机制结合了段式管理和页式管理的优点。简单来说，段页式管理机制就是把主存先分成若干个段，每个段又分成若干个页，也就是说 **段页式管理机制** 中段与段之间以及段的内部之间都是离散的。

> 总的来说：页是物理单位，段是逻辑单位。分页可以有效的提高内存的利用率，分段可以更好的满足用户的需求。



### 3、块表和多级页表

1. 快表和多级页表，这两个内容解决了页表管理中很重要的两个问题。

    1. 虚拟地址到物理地址的转换要快。
    2. 解决当虚拟地址空间大的时候，页表也会很大的问题。

2. **快表**

   ​    为了提高虚拟机地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器，其中的内容是页表的一部分或者全部内容。作为页表的 cache ，他的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时，CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

   ​    使用快表之后的地址转换流程是这样的：

    1. 根据虚拟地址中的页号查快表。
    2. 如果该页在快表中，直接从快表中读取相应的物理地址。
    3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中。
    4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

3. **多级页表**

   ​    引入多级页表的目的主要是为了避免把全部页表一直放在内存中占用过多的空间，特别是那些根本不需要的页表就不要保留在内存中。

   ​    多级页表属于时间换空间的经典场景。

### 4、分页机制和分段机制的共同点和区别

- **共同点**：
- 分页机制和分段机制都是为了提高内存利用率，减少内存碎片化。

- 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

- **区别**：

    - 页的大小是固定的，由操作系统决定，而段的大小不固定，取决于我们当前运行的程序。
    - 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

### 5、逻辑(虚拟)地址和物理地址

- **逻辑(虚拟)地址**
    - 由 CPU 在执行程序时生成的地址，是**进程 “看到” 的内存地址**，不直接对应物理内存硬件的实际位置。
    - 进程独立性：每个进程有自己独立的逻辑地址空间，进程 A 的 0x1000 地址和进程 B 的 0x1000 地址毫无关联，避免进程间内存干扰。
    - 非直接访问：逻辑地址无法直接用于访问物理内存，必须先转换为物理地址。
- **物理地址**
    - 计算机物理内存（如内存条）硬件本身的真实地址，是**内存芯片引脚能直接识别的地址**，对应内存单元的实际物理位置。
    - 硬件唯一性：物理地址由内存硬件决定，整个系统中每个物理地址唯一，直接对应硬件单元。
    - 直接访问性：只有物理地址能被内存控制器识别，用于读取 / 写入内存数据。

### 6、CPU 寻址

- **CPU 寻址**
    - 现代处理器使用的是一种称为 **虚拟寻址** 的寻址方式，也就是 CPU 将虚拟地址翻译为物理地址，而完成这个转换工作的是 CPU 中包含的一个被称为 **内存管理单元（MMU）** 的硬件。
    - 具体过程：**地址拆分**、**页表查询**、**地址拼接**、**内存访问**。

### 7、为什么需要虚拟地址空间

​		先从没有虚拟地址空间的时候说起，没有虚拟地址空间的时候，**程序直接访问和操作的都是物理内存**。但是这样存在很大的问题。

​		1、用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易破坏系统，造成操作系统的崩溃。

​		2、想要同时运行多个程序特别困难，比如想同时运行一个微信和一个QQ音乐，微信运行时，为 1xxx 的地址赋值

​				后，QQ音乐也同样给内存 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖之前的值，导致微信程序的崩溃。

​		通过虚拟地址访问内存有以下优势：

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理地址内存的内存缓冲区，也就是当物理内存不够使用时，内存管理器会将物理内存页（通常大小 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此之间隔离。一个进程中的代码无法更改正在由另一个进程或操作系统使用的物理内存。

## 四、虚拟内存

### 1、什么是虚拟内存

​		在我们平时使用的电脑特别是 Windows 系统十分常见。很多时候，我们使用了很多占内存的软件，这些软件占用的内存可能已将远远超出了我们电脑本身具有的物理内存。这正是因为 **虚拟内存** 的存在，通过虚拟内存可以让程序拥有超过系统物理内存大小的可以用内存空间。另外，**虚拟内存为每个进程提供了一个一致的，私有的地址空间，他让每个进程产生了一种自己在独享主存的错觉**。这样更加有效的管理内存并减少出错。虚拟内存的重要意义在于：**它定义了一个连续的虚拟孔吉纳，并且把内存扩展到硬盘空间。**

### 2、局部性原理

​		局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。也就是说，在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。

- **时间局部性**：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久之后该数据可能再次被访问。产生时间局部性的经典原因，是由于在程序中存在着大量的循环操作。
- **空间局部性**：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量，数组，表等形式簇集储存的。

### 3、虚拟存储器

​    所谓的虚拟存储器，是指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩展的一种存储器。



​    一般具有三大特征：

- **多次性**：是指一个作业中的程序和数据无需在作业运行时一次性的调入内存，而是被被允许分成多次调入内存允许。
-  **对换性**：是指一个作业中的程序和数据无需在作业运行时一直常驻内存，而是允许他们在作业运行时换入和唤出
- **虚拟性**：是指能够从逻辑上扩大容量，使用户看到的内存容量远大于实际内存容量。



### 4、虚拟内存的技术实现

​    **虚拟内存技术的实现，需要建立在离散分配内存管理方式的基础上** 。虚拟内存的实现有一下三种方式：

- **请求分页存储管理**：建立在分页系统之上，增加了请求分页功能和页面置换功能所形成的页式虚拟存储系统。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储器系统中，在作业开始运行之前，仅装入当前要执行的部分页面即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入主存，同时操作系统也可以将暂时不使用的页面置换到外存中。

- **请求分段存储器管理**：建立在分段系统之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可；在执行过程中，可以使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已经满了，而又需装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。

- **请求段页式存储管理**：

  > 请求分页和分页存储系统的不同
  >
  > 请求分页存储管理建立在分页管理之上，根本区别就是是否将程序全部地址空间都装入主存。



### 5、页面置换算法

​    地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断。

​    当发生缺页中断时，如果当前内存中没有空闲的页面，操作系统就必须在内存中选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。

- **OPT 页面置换算法（最佳页面置换算法）**：最佳页面置换算法所选择的被淘汰的页面将是以后永不使用的，或者是在很长在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。但是由于人们目前无法预知进程内存下的若干页面中那个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- **FIFO 页面置换算法（先进先出页面置换算法）**：总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU 页面置换算法（最近最久未使用页面置换算法）**：LRU 算法赋予每一个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当淘汰一个页面时，选择现有页面中 T 最大的，即最近最久未使用的页面予以淘汰。
- **LFU 页面置换算法 （最少使用页面置换算法）**：该置换算法选择在之前时期使用最少的页面作为淘汰页。